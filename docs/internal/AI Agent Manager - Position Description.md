# **AI Agent Manager**

**Organisation Unit:** Delivery  
**Reports to**: Head of AI Services  
**Has subordinates**: No  
(If they have subordinates, this position will implicitly have the “[Managers with Subordinates](https://docs.google.com/document/d/1k9r_8zrlvTlga12WkKY1Qs0gIziKvUH9v7zQuduszOg/view)” set of responsibilities attached to it, aside from those listed in this page.)

## **Overview**

The AI Agent Manager is responsible for ensuring our AI agents provide **accurate, helpful, and on-brand support** to customers. This role is defined by the repeatable process of optimizing, testing, and deploying effective AI agents across various client platforms (Gorgias, Zendesk, etc.). The Manager's success is achieved by transforming raw client knowledge into a **high-quality, AI-ready knowledge base** and driving continuous performance improvement through **data-driven RAGAS metrics**.

## **Key Responsibilities**

### **Context Engineering & Knowledge Governance**

* **Knowledge Base Construction:** Create and structure high-quality, AI-ready knowledge bases using **atomic markdown** with clear headings, ensuring content is accurate and brand-aligned.  
* **Guidance Creation:** Draft clear, machine-readable instructions for the AI on tone, escalation rules, and definitions (Glossary & Definitions) to prevent confusion.  
* **Process Initiation (Discovery):** Execute Client Discovery & Onboarding, including **Kickoff Alignment** with stakeholders to define scope/metrics and perform **Gap Analysis** to identify knowledge gaps.  
* **Documentation:** Maintain all materials, including context guides and process SOPs, in a central, version-controlled repository.

### **AI Testing, Benchmarking & Deployment**

* **Benchmark Creation:** Create a set of test questions and ideal answers from real customer queries to establish accuracy benchmarks.  
* **Staging Evaluation:** Execute the **Staging Test** process using the Influx People App to verify AI accuracy in a safe environment, specifically tracking **RAGAS metrics** (Faithfulness ≥0.9 and Semantic Similarity ≥0.7).  
* **Production Validation:** Execute the **Production Test** process, running the same benchmarks through the live AI agent to validate performance in the client's production environment.  
* **Deployment & Handover:** Deploy the approved knowledge base, confirm escalation triggers are working, and secure **Client POC approval** for full production deployment.

### **Continuous Improvement & Optimization**

* **Performance Monitoring:** Track key performance indicators (KPIs) (CSAT, AI Answered %, Handover %, Close %) on dashboards and set up alerts for unexpected drops in performance.  
* **Optimization Flywheel:** Implement the continuous improvement flywheel: **Analyze** performance data to identify patterns/gaps, **Train** by updating knowledge and guidance, **Test** changes, and **Deploy** in a measured way.  
* **Feedback Integration:** Conduct **iterative** feedback from CSAs, Team Leaders or other Stakeholders about AI services management or improvement (e.g. flag critical gaps immediately).

### **Collaboration & Reporting**

* **Cross-Team Integration:** Work closely with stakeholders (SDMs, TLs, Client POCs) to ensure the AI Agent seamlessly integrates with human operations.  
* **Operational Reporting:** Share performance insights, progress, and action plans with internal teams and clients, including clear status updates on deployment and maintenance.

### ***Constraints***

*The AI Agent Manager is accountable for the **design, technical integrity, and high-performance accuracy of the AI Agent's knowledge base and testing protocols**. This role's authority is advisory and focused on enablement. The Manager is **not solely responsible** for: **final decisions on client support policy** (which rests with the Client's POC), the **long-term performance management** of human agents (CSAs/TLs), or **the core functionality of client-facing platforms** (Gorgias, Zendesk, etc.).*

## **Evaluation Criteria**

### **Context Engineering & Knowledge Governance**

* **Knowledge Base Construction:** How effectively are high-quality, AI-ready knowledge bases created and maintained using **atomic markdown**, ensuring content is accurate and brand-aligned?  
* **Guidance Creation:** How effectively do you draft clear, machine-readable instructions on tone, escalation rules, and definitions (Glossary) to **prevent AI confusion and misalignment**?  
* **Process Initiation (Discovery):** What evidence (e.g., meeting minutes, final document sign-off) confirms that a thorough **Gap Analysis** was performed and **Kickoff Alignment** was achieved with stakeholders?  
* **Documentation:** Do you maintain all materials (guides, SOPs, context files) in a **central, version-controlled repository**?

### **AI Testing, Benchmarking & Deployment**

* **Staging Evaluation:** Are the staging tests consistently meeting the minimum **Faithfulness score (≥0.9)** and **Semantic Similarity score (≥0.7)**?  
* **Production Validation:** Did **all live benchmarks** meet or exceed the performance thresholds in the production environment?  
* **Deployment & Handover: Has every AI agent deployed received Client POC approval** after comprehensive review and confirmation that escalation triggers are working?

### **Continuous Improvement & Optimization**

* **Performance Monitoring, KPI Impact:** What is the measurable improvement in key client metrics (e.g., **CSAT, AI Answered %, Handover %, Close %**) directly attributed to your AI agent optimization?  
* **Optimization Flywheel:** How effectively is the **Analyze, Train, Test, and Deploy** continuous improvement cycle implemented to maintain strong AI performance?  
* **Feedback Integration:** Was iterative feedback effectively gathered from stakeholders to identify actionable management or service improvements?

### **Collaboration & Reporting**

* **Cross-Team Integration:** How effectively do you collaborate with stakeholders (SDMs, TLs, Client POCs) to ensure the AI Agent seamlessly integrates with human operations?  
* **Operational Reporting:** How accurately and timely do you share performance insights and progress with internal teams and clients?

## **Requirements**

* **AI & Technical Fluency:** Proven ability to build and maintain AI knowledge bases, conduct data analysis, and utilize specialized AI evaluation frameworks (RAGAS).  
* **Tool Proficiency:** Experience with or demonstrated ability to quickly master client platforms (e.g., **Gorgias, Zendesk, Forethought**) and internal tools (Influx People App).  
* **Process Discipline:** Strong skills in project management, process mapping, and maintaining detailed, version-controlled documentation.

### **Required Equipments**

**High-Performance Computing System** required to run complex analytical software (e.g., SQL, BI Tools) and manage large datasets. High-quality headset for clear communication.

## **Working Conditions**

**Remote and Flexible:** Operates in a remote environment. Requires **flexible working hours** to collaborate effectively across time zones with cross-functional teams and stakeholders. Operates under pressure with direct accountability for the **accuracy and integrity** of data-driven insights.

# **Changelog**

| Date | PIC | Line Manager | Action |
| :---- | :---- | :---- | :---- |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |

